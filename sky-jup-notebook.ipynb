{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/01/25 13:55:16 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "from pyspark.sql import SparkSession, Row\n",
    "from opensky_api import OpenSkyApi\n",
    "from noaa_sdk import NOAA\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType, ArrayType, TimestampNTZType, MapType\n",
    "from pyspark.sql.functions import col, explode_outer, from_json, lit, concat\n",
    "\n",
    "from schemas.noaa import forecast_schema\n",
    "from schemas.opensky import states_schema\n",
    "from utils.helper_functions import get_parameters\n",
    "from utils.flatten_json import flatten\n",
    "\n",
    "noaa = NOAA()\n",
    "\n",
    "open_sky = OpenSkyApi(username='jasminepate', password='<password>')\n",
    "spark = SparkSession.builder.appName('read_json').getOrCreate()\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_output = noaa.points_forecast(40.7314, -73.8656, type='forecastGridData')\n",
    "\n",
    "with open('raw_data/noaa_data.json', 'w') as outfile:\n",
    "        outfile.write(json.dumps(forecast_output))\n",
    "noaa.get_observations(30281, 'US')\n",
    "noaa.get_forecasts(30281, 'US')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os = open_sky.get_states()\n",
    "\n",
    "# convert from defaultdict to json\n",
    "os_json = json.dumps(os.states, default=lambda o: o.__dict__, \n",
    "            sort_keys=True, indent=4)\n",
    "\n",
    "with open('raw_data/opensky_data.json', 'w') as outfile:\n",
    "        outfile.write(os_json)\n",
    "\n",
    "with open('raw_data/opensky_lat_long.txt', 'w') as outfile:\n",
    "        for i in os.states:\n",
    "            outfile.write(f'{i.latitude}, {i.longitude} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from schemas.opensky import states_schema\n",
    "\n",
    "test = spark.read.load('raw_data/opensky_data.json', format='json', header=\"true\", schema=states_schema)\n",
    "test.show(5, False) # Show the first 5 without truncating\n",
    "\n",
    "for i in os.states:\n",
    "    noaa.points_forecast(i.latitude, i.longitude, type='forecastGridData')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read Operations\n",
    "df = spark.read.json('raw_data/opensky_data.json', multiLine=True).option(\"header\", True) # Option 1\n",
    "df = spark.read.format('json').option('header', True).load(\"raw_data/opensky_data.json\", multiline=True) # Option 2\n",
    "df = spark.read.load('raw_data/opensky_data.json', format='json', header=\"true\") # Option 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Operations\n",
    "df.select('latitude', 'longitude').write.save('lat_long.parquet', format='parquet') # Option 1\n",
    "df.write.format(\"parquet\").save('lat_long.parquet') # Option 2\n",
    "\n",
    "# Bucket by country \n",
    "df.write.bucketBy(10, 'origin_country').sortBy('catagory').saveAsTable(\"country_bucketed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary Views\n",
    "\n",
    "# Register the DataFrame as a SQL temporary view. Will terminate if the session end\n",
    "df.createOrReplaceTempView(\"forecast\")\n",
    "\n",
    "# Global view is preserved until the spark application terminates\n",
    "df.createGlobalTempView('forecast')\n",
    "\n",
    "# Global cross-session\n",
    "spark.newSession().sql(\"SELECT * FROM global_temp.forecast\").show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL \n",
    "\n",
    "# On DataFrames\n",
    "df.show()\n",
    "df.select(\"latitude\").show()\n",
    "df.filter(df[\"vertical_rate\"] > 0).show()\n",
    "df.groupBy(\"category\").count().show()\n",
    "\n",
    "# Temp Views\n",
    "spark.sql(\"SELECT * FROM forecast\")\n",
    "spark.sql(\"SELECT * FROM global_temp.forecast\").show()\n",
    "\n",
    "# Directly from files\n",
    "spark.sql('SELECT * FROM parquet.`opensky_data.parquet`')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark.sparkContext\n",
    "\n",
    "lines = sc.textFile('raw_data/opensky_lat_long.txt')\n",
    "parts = lines.map(lambda l: l.split(','))\n",
    "lat_long = parts.map(lambda p: Row(latitude=float(p[0]), longitude=float(p[1])))\n",
    "\n",
    "df_lat_long = spark.createDataFrame(lat_long)\n",
    "df_lat_long.createOrReplaceTempView(\"latitude_longitude\")\n",
    "\n",
    "spark.sql(\"SELECT * FROM latitude_longitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"multiline\", \"true\").option('header', 'true').json('raw_data/noaa_data.json')\n",
    "af = flatten(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "52679e782473809bf96d253b5157c08439069f7696d3e05ccc132ff5e7fa07be"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
